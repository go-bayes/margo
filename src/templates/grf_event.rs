/// GRF Event Study (multi-outcome wave) project templates
///
/// for longitudinal event studies where a single exposure is followed
/// by multiple outcome waves to track effect trajectories over time
///
/// returns a vector of (filename, content) tuples

#[allow(dead_code)]
pub fn get_template_files(project_name: &str) -> Vec<(String, String)> {
    vec![
        ("study.toml".to_string(), study_toml(project_name)),
        ("README.md".to_string(), readme(project_name)),
        (".gitignore".to_string(), gitignore()),
        ("01-data-prep.R".to_string(), script_01()),
        ("02-wide-format.R".to_string(), script_02()),
        ("03-causal-forest.R".to_string(), script_03()),
        ("04-trajectory-plot.R".to_string(), script_04()),
        ("05-heterogeneity.R".to_string(), script_05()),
        ("06-positivity.R".to_string(), script_06()),
        ("07-tables.R".to_string(), script_07()),
    ]
}

/// get template files with config values pre-filled
pub fn get_template_files_with_config(
    project_name: &str,
    pull_data: &str,
    push_mods: &str,
    exposure: &str,
    baseline_vars: &[String],
    outcome_var: &str,
    outcome_waves: &[String],
    reference_wave: &str,
) -> Vec<(String, String)> {
    vec![
        ("study.toml".to_string(), study_toml_configured(
            project_name,
            pull_data,
            push_mods,
            exposure,
            baseline_vars,
            outcome_var,
            outcome_waves,
            reference_wave,
        )),
        ("README.md".to_string(), readme(project_name)),
        (".gitignore".to_string(), gitignore()),
        ("01-data-prep.R".to_string(), script_01()),
        ("02-wide-format.R".to_string(), script_02()),
        ("03-causal-forest.R".to_string(), script_03()),
        ("04-trajectory-plot.R".to_string(), script_04()),
        ("05-heterogeneity.R".to_string(), script_05()),
        ("06-positivity.R".to_string(), script_06()),
        ("07-tables.R".to_string(), script_07()),
    ]
}

/// generate study.toml with config values pre-filled
fn study_toml_configured(
    project_name: &str,
    pull_data: &str,
    push_mods: &str,
    exposure: &str,
    baseline_vars: &[String],
    outcome_var: &str,
    outcome_waves: &[String],
    reference_wave: &str,
) -> String {
    let baseline_str = format_var_array(baseline_vars);
    let outcome_waves_str = format_string_array(outcome_waves);

    format!(
        r####"# {project_name} - GRF Event Study configuration
# longitudinal event study with multiple outcome waves
# generated by margo

[paths]
pull_data = "{pull_data}"
push_mods = "{push_mods}"

[waves]
# event study design: baseline, single exposure, multiple outcomes
# use time_factor values: Time 1 = 2009, Time 3 = 2011, Time 10 = 2018, etc.
baseline = "Time 1"
exposure = "Time 3"
outcome  = {outcome_waves_str}

[outcome_trajectory]
# reference wave for time calculations (t=0)
reference_wave = "{reference_wave}"
time_label = "years_post_event"

[exposure]
name = "{exposure}"
type = "binary"
# for binary exposures, specify the exposed value
exposed_value = 1
# human-readable labels
label_exposed = "Exposed"
label_control = "Control"

[outcomes]
# single outcome variable measured across all outcome waves
var = "{outcome_var}"
standardise = true

[baseline]
vars = {baseline_str}

[labels.exposure]
{exposure} = "{exposure_label}"

[labels.outcome]
{outcome_var} = "{outcome_label}"

[titles]
nice_exposure_name = "{exposure_label}"
nice_outcome_name  = "{outcome_label}"
filename_prefix    = "grf_event_{project_name}"

[eligibility]
# sample restrictions
enabled = false
require_baseline_outcome = true
require_exposure_measured = true

[censoring]
# handle panel attrition
enabled = true
use_ipcw = true

[imputation]
method = "none"

[weights]
trim_quantile = 0.99

[grf]
seed = 42
stabilize_splits = true
min_node_size = 20
num_trees = 2000

[model]
# minimum sample requirements for each wave
min_total_n = 50
min_exposed_n = 10
min_control_n = 10

[trajectory_plot]
show_ci = true
ci_level = 0.95
point_size = 3
line_size = 1
ribbon_alpha = 0.2
"####,
        project_name = project_name,
        pull_data = pull_data,
        push_mods = push_mods,
        exposure = exposure,
        exposure_label = exposure.replace('_', " "),
        outcome_var = outcome_var,
        outcome_label = outcome_var.replace('_', " "),
        outcome_waves_str = outcome_waves_str,
        reference_wave = reference_wave,
        baseline_str = baseline_str,
    )
}

/// format a vec of strings as a TOML array
fn format_var_array(vars: &[String]) -> String {
    if vars.is_empty() {
        return "[]".to_string();
    }
    let items: Vec<String> = vars.iter().map(|v| format!("\"{}\"", v)).collect();
    format!("[\n  {}\n]", items.join(",\n  "))
}

/// format a vec of strings as a single-line TOML array
fn format_string_array(vars: &[String]) -> String {
    if vars.is_empty() {
        return "[]".to_string();
    }
    let items: Vec<String> = vars.iter().map(|v| format!("\"{}\"", v)).collect();
    format!("[{}]", items.join(", "))
}

#[allow(dead_code)]
fn study_toml(project_name: &str) -> String {
    format!(
        r####"# {project_name} - GRF Event Study configuration
# longitudinal event study with multiple outcome waves
# generated by margo

[paths]
# path to source data (read-only)
pull_data = "/path/to/your/source/data"
# path to save outputs (outside git)
push_mods = "/path/to/your/output/directory"

[waves]
# wave column name in your data
# use "time_factor" for "Time X" format, or "wave" for year format
wave_col = "time_factor"

# event study design: baseline, single exposure, multiple outcome waves
# Time 1 = 2009, Time 3 = 2011, Time 10 = 2018, Time 15 = 2023
baseline = "Time 1"
exposure = "Time 3"
outcome  = ["Time 3", "Time 4", "Time 5", "Time 6", "Time 7", "Time 8", "Time 9", "Time 10", "Time 11", "Time 12", "Time 13", "Time 14", "Time 15"]

[outcome_trajectory]
# reference wave for time calculations (t=0 for "years post event")
reference_wave = "Time 3"
time_label = "years_post_event"

[exposure]
# exposure variable (typically binary for event studies)
name = "equake_affected_earthquake"
type = "binary"
exposed_value = 1
label_exposed = "Earthquake Affected"
label_control = "Not Affected"

[outcomes]
# single outcome variable measured at each outcome wave
var = "religion_religious"
standardise = true

[baseline]
# baseline confounders (measured before exposure)
# include the outcome at baseline for adjustment
vars = [
  "age",
  "male",
  "eth_cat",
  "education_level_coarsen",
  "nz_dep2006"
]

[labels.exposure]
event_exposed = "Event Exposure"

[labels.outcome]
outcome_variable = "Outcome"

[titles]
nice_exposure_name = "Event Exposure"
nice_outcome_name  = "Outcome"
filename_prefix    = "grf_event_{project_name}"

[eligibility]
# sample restrictions
enabled = false
# require outcome measured at baseline
require_baseline_outcome = true
# require exposure status measured
require_exposure_measured = true

[censoring]
# handle panel attrition across waves
enabled = true
# use inverse probability of censoring weights
use_ipcw = true

[imputation]
# imputation method: "none", "mice", "carry_forward"
method = "none"

[weights]
# quantile for weight trimming
trim_quantile = 0.99

[grf]
# causal forest hyperparameters
seed = 42
stabilize_splits = true
min_node_size = 20
num_trees = 2000

[model]
# minimum sample requirements for each wave analysis
min_total_n = 50
min_exposed_n = 10
min_control_n = 10

[trajectory_plot]
# effect trajectory visualisation settings
show_ci = true
ci_level = 0.95
point_size = 3
line_size = 1
ribbon_alpha = 0.2
"####,
        project_name = project_name
    )
}

fn readme(project_name: &str) -> String {
    format!(
        r####"# {project_name}

GRF Event Study: longitudinal causal inference with multiple outcome waves.

## Design

This template implements an **event study design** where:
- A single baseline wave provides pre-event confounders
- A single exposure wave identifies affected vs unaffected individuals
- Multiple outcome waves track the effect trajectory over time

## Script order

| Script | Purpose |
|--------|---------|
| 01-data-prep.R | data prep, identify eligible sample |
| 02-wide-format.R | create analysis datasets for each outcome wave |
| 03-causal-forest.R | fit causal forests for each wave, collect ATEs |
| 04-trajectory-plot.R | visualise effect trajectory over time |
| 05-heterogeneity.R | heterogeneity tests (optional, for selected waves) |
| 06-positivity.R | check positivity at each wave |
| 07-tables.R | summary statistics tables |

## Configuration

Edit `study.toml` with your study-specific settings:
- Set wave identifiers in `[waves]`
- Define the reference wave in `[outcome_trajectory]`
- Specify exposure and outcome variables
- List baseline confounders

## Requirements

- R >= 4.0
- margot package: `devtools::install_github("go-bayes/margot")`
"####,
        project_name = project_name
    )
}

fn gitignore() -> String {
    r####"# data files
*.qs
*.rds
*.csv
*.xlsx

# R artifacts
.Rhistory
.Rdata
.Ruserdata
.RData

# output files
*.pdf
*.png
*.html

# renv
renv/library/
renv/staging/
renv/python/

# IDE
.Rproj.user/
*.Rproj

# OS
.DS_Store
Thumbs.db
"####
    .to_string()
}

fn script_01() -> String {
    r####"# 01-data-prep.R
# data preparation for GRF event study
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
 tidyverse, qs, here, data.table, naniar, skimr,
  kableExtra, ggplot2, janitor, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# read config -------------------------------------------------------------
config_path <- here::here("study.toml")
if (file.exists(config_path)) {
  cfg <- RcppTOML::parseTOML(config_path)
  cli::cli_alert_info(sprintf("loaded config from %s", config_path))
} else {
  stop("config not found: study.toml")
}

# paths -------------------------------------------------------------------
pull_path <- fs::path_expand(require_cfg(cfg$paths$pull_data, "set paths.pull_data"))
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

if (!dir.exists(push_mods)) {
  dir.create(push_mods, recursive = TRUE)
  cli::cli_alert_info(sprintf("created output directory: %s", push_mods))
}

# wave definitions --------------------------------------------------------
wave_col <- cfg$waves$wave_col %||% "time_factor"
baseline_wave <- require_cfg(cfg$waves$baseline, "set waves.baseline")
exposure_wave <- require_cfg(cfg$waves$exposure, "set waves.exposure")
outcome_waves <- require_cfg(cfg$waves$outcome, "set waves.outcome")
reference_wave <- cfg$outcome_trajectory$reference_wave %||% outcome_waves[1]
time_label <- cfg$outcome_trajectory$time_label %||% "years_post_event"

cli::cli_alert_info(sprintf("using wave column: %s", wave_col))

# variable definitions ----------------------------------------------------
name_exposure <- require_cfg(cfg$exposure$name, "set exposure.name")
exposed_value <- cfg$exposure$exposed_value %||% 1
outcome_var <- require_cfg(cfg$outcomes$var, "set outcomes.var")
baseline_vars <- require_cfg(cfg$baseline$vars, "set baseline.vars")

cli::cli_h1("configuration loaded")
cli::cli_alert_info(sprintf("baseline: %s | exposure: %s", baseline_wave, exposure_wave))
cli::cli_alert_info(sprintf("outcome waves: %s", paste(outcome_waves, collapse = ", ")))
cli::cli_alert_info(sprintf("reference wave (t=0): %s", reference_wave))

# save definitions --------------------------------------------------------
margot::here_save(wave_col, "wave_col")
margot::here_save(baseline_wave, "baseline_wave")
margot::here_save(exposure_wave, "exposure_wave")
margot::here_save(outcome_waves, "outcome_waves")
margot::here_save(reference_wave, "reference_wave")
margot::here_save(time_label, "time_label")
margot::here_save(name_exposure, "name_exposure")
margot::here_save(exposed_value, "exposed_value")
margot::here_save(outcome_var, "outcome_var")
margot::here_save(baseline_vars, "baseline_vars")

# load data ---------------------------------------------------------------
# TODO: adjust to match your data loading pattern
dat <- margot::here_read_qs("nzavs_data", pull_path)
cli::cli_alert_info(sprintf("loaded %d rows", nrow(dat)))

# initial prep ------------------------------------------------------------
dat_prep <- dat |>
  arrange(id, .data[[wave_col]]) |>
  margot::remove_numeric_attributes() |>
  droplevels()

# identify eligible sample ------------------------------------------------
# must have: baseline data, exposure measured, at least one outcome wave

cli::cli_h1("identifying eligible sample")

# ids with baseline data
ids_baseline <- dat_prep |>
  filter(.data[[wave_col]] == baseline_wave, year_measured == 1) |>
  pull(id) |>
  unique()
cli::cli_alert_info(sprintf("participants at baseline: %d", length(ids_baseline)))

# ids with exposure measured
ids_exposure <- dat_prep |>
  filter(.data[[wave_col]] == exposure_wave, !is.na(.data[[name_exposure]])) |>
  pull(id) |>
  unique()
cli::cli_alert_info(sprintf("participants with exposure measured: %d", length(ids_exposure)))

# eligible: intersection
ids_eligible <- intersect(ids_baseline, ids_exposure)
cli::cli_alert_info(sprintf("eligible sample: %d", length(ids_eligible)))

# filter to eligible
dat_eligible <- dat_prep |>
  filter(id %in% ids_eligible) |>
  droplevels()

# create exposure indicator -----------------------------------------------
dat_exposure <- dat_eligible |>
  filter(.data[[wave_col]] == exposure_wave) |>
  select(id, all_of(name_exposure)) |>
  mutate(
    exposed = as.integer(.data[[name_exposure]] == exposed_value)
  )

n_exposed <- sum(dat_exposure$exposed, na.rm = TRUE)
n_control <- sum(dat_exposure$exposed == 0, na.rm = TRUE)
cli::cli_alert_info(sprintf("exposed: %d | control: %d", n_exposed, n_control))

# baseline confounders ----------------------------------------------------
dat_baseline <- dat_eligible |>
  filter(.data[[wave_col]] == baseline_wave) |>
  select(id, any_of(baseline_vars), all_of(outcome_var))

# rename baseline outcome for clarity
names(dat_baseline)[names(dat_baseline) == outcome_var] <- paste0("baseline_", outcome_var)

# check for missing baseline outcome if required
if (cfg$eligibility$require_baseline_outcome %||% TRUE) {
  baseline_outcome_col <- paste0("baseline_", outcome_var)
  ids_with_baseline_outcome <- dat_baseline |>
    filter(!is.na(.data[[baseline_outcome_col]])) |>
    pull(id)

  dat_baseline <- dat_baseline |>
    filter(id %in% ids_with_baseline_outcome)

  cli::cli_alert_info(sprintf("with baseline outcome: %d", nrow(dat_baseline)))
}

# merge baseline + exposure -----------------------------------------------
dat_analysis_base <- dat_baseline |>
  inner_join(dat_exposure |> select(id, exposed), by = "id")

cli::cli_h1("analysis base sample")
cli::cli_alert_info(sprintf("n = %d", nrow(dat_analysis_base)))
cli::cli_alert_info(sprintf("exposed: %d | control: %d",
  sum(dat_analysis_base$exposed),
  sum(dat_analysis_base$exposed == 0)))

# save --------------------------------------------------------------------
margot::here_save(dat_analysis_base, "dat_analysis_base", push_mods)
margot::here_save(dat_eligible, "dat_eligible", push_mods)
margot::here_save(ids_eligible, "ids_eligible", push_mods)

cli::cli_h1("script 01 complete")
"####
    .to_string()
}

fn script_02() -> String {
    r####"# 02-wide-format.R
# create analysis datasets for each outcome wave
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, data.table, grf, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# load saved objects ------------------------------------------------------
dat_analysis_base <- margot::here_read("dat_analysis_base", push_mods)
dat_eligible <- margot::here_read("dat_eligible", push_mods)
wave_col <- margot::here_read("wave_col")
outcome_waves <- margot::here_read("outcome_waves")
outcome_var <- margot::here_read("outcome_var")
reference_wave <- margot::here_read("reference_wave")
time_label <- margot::here_read("time_label")
baseline_vars <- margot::here_read("baseline_vars")

cli::cli_h1("creating wave-specific datasets")

# helper to extract wave number from "Time X" format or use year directly
extract_wave_number <- function(wave_val) {
  if (grepl("^Time ", wave_val)) {
    as.numeric(gsub("Time ", "", wave_val))
  } else {
    as.numeric(wave_val)
  }
}

# function to create dataset for a single outcome wave --------------------
create_wave_dataset <- function(outcome_wave) {
  cli::cli_alert_info(sprintf("processing wave: %s", outcome_wave))

  # get outcome at this wave
  dat_outcome <- dat_eligible |>
    filter(.data[[wave_col]] == outcome_wave, year_measured == 1) |>
    select(id, outcome = all_of(outcome_var))

  # merge with baseline + exposure
  dat_wave <- dat_analysis_base |>
    inner_join(dat_outcome, by = "id") |>
    filter(!is.na(outcome))

  # calculate time since reference wave (extract wave numbers from "Time X")
  ref_numeric <- extract_wave_number(reference_wave)
  wave_numeric <- extract_wave_number(outcome_wave)
  dat_wave$time_since_event <- wave_numeric - ref_numeric
  dat_wave$outcome_wave <- outcome_wave

  # standardise outcome if configured
  if (cfg$outcomes$standardise %||% TRUE) {
    dat_wave$outcome_z <- scale(dat_wave$outcome)[, 1]
  } else {
    dat_wave$outcome_z <- dat_wave$outcome
  }

  cli::cli_alert_success(sprintf("  n = %d (exposed: %d, control: %d)",
    nrow(dat_wave),
    sum(dat_wave$exposed),
    sum(dat_wave$exposed == 0)))

  dat_wave
}

# create datasets for all waves -------------------------------------------
wave_datasets <- map(outcome_waves, create_wave_dataset)
names(wave_datasets) <- outcome_waves

# summary -----------------------------------------------------------------
wave_summary <- map_dfr(outcome_waves, function(w) {
  d <- wave_datasets[[w]]
  tibble(
    wave = w,
    n_total = nrow(d),
    n_exposed = sum(d$exposed),
    n_control = sum(d$exposed == 0),
    time_since_event = unique(d$time_since_event)
  )
})

print(wave_summary)

# save --------------------------------------------------------------------
margot::here_save(wave_datasets, "wave_datasets", push_mods)
margot::here_save(wave_summary, "wave_summary", push_mods)

cli::cli_h1("script 02 complete - wave datasets created")
"####
    .to_string()
}

fn script_03() -> String {
    r####"# 03-causal-forest.R
# fit causal forests for each outcome wave
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, data.table, grf, cli, glue, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# grf settings
grf_seed <- cfg$grf$seed %||% 42
grf_stabilize <- cfg$grf$stabilize_splits %||% TRUE
grf_min_node <- cfg$grf$min_node_size %||% 20
grf_num_trees <- cfg$grf$num_trees %||% 2000

# minimum sample requirements
min_total_n <- cfg$model$min_total_n %||% 50
min_exposed_n <- cfg$model$min_exposed_n %||% 10
min_control_n <- cfg$model$min_control_n %||% 10

# load saved objects ------------------------------------------------------
wave_datasets <- margot::here_read("wave_datasets", push_mods)
wave_summary <- margot::here_read("wave_summary", push_mods)
outcome_waves <- margot::here_read("outcome_waves")
baseline_vars <- margot::here_read("baseline_vars")
outcome_var <- margot::here_read("outcome_var")
time_label <- margot::here_read("time_label")

cli::cli_h1("fitting causal forests for each wave")

# function to fit causal forest for one wave ------------------------------
fit_wave_forest <- function(wave_name) {
  cli::cli_alert_info(sprintf("fitting forest for wave: %s", wave_name))

  dat <- wave_datasets[[wave_name]]

  # check minimum sample sizes
  n_total <- nrow(dat)
  n_exposed <- sum(dat$exposed)
  n_control <- sum(dat$exposed == 0)

  if (n_total < min_total_n || n_exposed < min_exposed_n || n_control < min_control_n) {
    cli::cli_alert_warning(sprintf("  skipping: insufficient sample (n=%d, exposed=%d, control=%d)",
      n_total, n_exposed, n_control))
    return(NULL)
  }

  # prepare data
  # covariate matrix: baseline vars + baseline outcome
  baseline_outcome_col <- paste0("baseline_", outcome_var)
  covariate_cols <- c(baseline_vars, baseline_outcome_col)
  covariate_cols <- covariate_cols[covariate_cols %in% names(dat)]

  X <- dat |>
    select(all_of(covariate_cols)) |>
    mutate(across(everything(), as.numeric)) |>
    as.matrix()

  Y <- dat$outcome_z
  W <- dat$exposed

  # fit causal forest
  forest <- tryCatch({
    grf::causal_forest(
      X = X,
      Y = Y,
      W = W,
      seed = grf_seed,
      stabilize.splits = grf_stabilize,
      min.node.size = grf_min_node,
      num.trees = grf_num_trees
    )
  }, error = function(e) {
    cli::cli_alert_danger(sprintf("  error fitting forest: %s", e$message))
    return(NULL)
  })

  if (is.null(forest)) return(NULL)

  # get ATE
  ate <- grf::average_treatment_effect(forest)

  # get individual treatment effects
  tau_hat <- predict(forest)$predictions

  result <- list(
    wave = wave_name,
    time_since_event = unique(dat$time_since_event),
    n_total = n_total,
    n_exposed = n_exposed,
    n_control = n_control,
    ate_estimate = ate["estimate"],
    ate_se = ate["std.err"],
    ate_ci_lower = ate["estimate"] - 1.96 * ate["std.err"],
    ate_ci_upper = ate["estimate"] + 1.96 * ate["std.err"],
    tau_hat = tau_hat,
    forest = forest
  )

  cli::cli_alert_success(sprintf("  ATE = %.3f (SE = %.3f)",
    result$ate_estimate, result$ate_se))

  result
}

# fit forests for all waves -----------------------------------------------
forest_results <- map(outcome_waves, fit_wave_forest)
names(forest_results) <- outcome_waves

# remove NULL results (waves that were skipped)
forest_results <- compact(forest_results)

cli::cli_alert_info(sprintf("successfully fitted %d forests", length(forest_results)))

# compile ATE trajectory --------------------------------------------------
ate_trajectory <- map_dfr(forest_results, function(r) {
  tibble(
    wave = r$wave,
    time_since_event = r$time_since_event,
    n_total = r$n_total,
    n_exposed = r$n_exposed,
    n_control = r$n_control,
    ate = r$ate_estimate,
    se = r$ate_se,
    ci_lower = r$ate_ci_lower,
    ci_upper = r$ate_ci_upper
  )
}) |>
  arrange(time_since_event)

print(ate_trajectory)

# save --------------------------------------------------------------------
margot::here_save(forest_results, "forest_results", push_mods)
margot::here_save(ate_trajectory, "ate_trajectory", push_mods)

cli::cli_h1("script 03 complete - causal forests fitted")
"####
    .to_string()
}

fn script_04() -> String {
    r####"# 04-trajectory-plot.R
# visualise effect trajectory over time
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, ggplot2, patchwork, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# plot settings
show_ci <- cfg$trajectory_plot$show_ci %||% TRUE
ci_level <- cfg$trajectory_plot$ci_level %||% 0.95
point_size <- cfg$trajectory_plot$point_size %||% 3
line_size <- cfg$trajectory_plot$line_size %||% 1
ribbon_alpha <- cfg$trajectory_plot$ribbon_alpha %||% 0.2

# labels
time_label <- cfg$outcome_trajectory$time_label %||% "years_post_event"
nice_exposure <- cfg$titles$nice_exposure_name %||% "Exposure"
nice_outcome <- cfg$titles$nice_outcome_name %||% "Outcome"

# load saved objects ------------------------------------------------------
ate_trajectory <- margot::here_read("ate_trajectory", push_mods)
wave_summary <- margot::here_read("wave_summary", push_mods)

cli::cli_h1("creating trajectory plots")

# main trajectory plot ----------------------------------------------------
p_trajectory <- ggplot(ate_trajectory, aes(x = time_since_event, y = ate)) +
  # reference line at zero
  geom_hline(yintercept = 0, linetype = "dashed", colour = "grey50", linewidth = 0.5) +
  # confidence ribbon
  {if (show_ci) geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper),
                            alpha = ribbon_alpha, fill = "steelblue")} +
  # line
  geom_line(colour = "steelblue", linewidth = line_size) +
  # points
  geom_point(colour = "steelblue", size = point_size) +
  # labels

  labs(
    title = sprintf("Effect of %s on %s Over Time", nice_exposure, nice_outcome),
    subtitle = "Average Treatment Effect (ATE) with 95% confidence intervals",
    x = gsub("_", " ", time_label) |> tools::toTitleCase(),
    y = "ATE (standardised units)"
  ) +
  # theme
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

print(p_trajectory)

# sample size over time ---------------------------------------------------
p_sample <- ggplot(ate_trajectory, aes(x = time_since_event)) +
  geom_col(aes(y = n_total), fill = "grey70", alpha = 0.7) +
  geom_text(aes(y = n_total, label = n_total), vjust = -0.5, size = 3) +
  labs(
    title = "Sample Size by Wave",
    x = gsub("_", " ", time_label) |> tools::toTitleCase(),
    y = "N"
  ) +
  theme_minimal(base_size = 12) +
  theme(panel.grid.minor = element_blank())

print(p_sample)

# combined plot -----------------------------------------------------------
p_combined <- p_trajectory / p_sample +
  plot_layout(heights = c(3, 1))

print(p_combined)

# save plots --------------------------------------------------------------
margot::margot_save_png(p_trajectory, base_filename = "trajectory_ate", dir_path = push_mods)
margot::margot_save_png(p_sample, base_filename = "trajectory_sample", dir_path = push_mods)
margot::margot_save_png(p_combined, base_filename = "trajectory_combined", dir_path = push_mods)

margot::here_save(p_trajectory, "plot_trajectory", push_mods)
margot::here_save(p_combined, "plot_combined", push_mods)

cli::cli_h1("script 04 complete - trajectory plots saved")
"####
    .to_string()
}

fn script_05() -> String {
    r####"# 05-heterogeneity.R
# heterogeneity tests for selected waves
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, grf, kableExtra, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# load saved objects ------------------------------------------------------
forest_results <- margot::here_read("forest_results", push_mods)
ate_trajectory <- margot::here_read("ate_trajectory", push_mods)

cli::cli_h1("heterogeneity analysis")

# select waves for heterogeneity analysis ---------------------------------
# by default, analyse waves with significant effects
significant_waves <- ate_trajectory |>
  filter(ci_lower > 0 | ci_upper < 0) |>
  pull(wave)

if (length(significant_waves) == 0) {
  cli::cli_alert_warning("no waves with statistically significant effects")
  cli::cli_alert_info("analysing wave with largest absolute effect instead")
  significant_waves <- ate_trajectory |>
    slice_max(abs(ate), n = 1) |>
    pull(wave)
}

cli::cli_alert_info(sprintf("analysing heterogeneity for waves: %s",
  paste(significant_waves, collapse = ", ")))

# heterogeneity tests for each selected wave ------------------------------
hetero_results <- map(significant_waves, function(wave_name) {
  cli::cli_alert_info(sprintf("wave: %s", wave_name))

  result <- forest_results[[wave_name]]
  if (is.null(result)) return(NULL)

  forest <- result$forest

  # test for heterogeneity using RATE
  rate_result <- tryCatch({
    grf::rank_average_treatment_effect(forest)
  }, error = function(e) {
    cli::cli_alert_warning(sprintf("  RATE failed: %s", e$message))
    NULL
  })

  # variable importance
  var_imp <- tryCatch({
    grf::variable_importance(forest) |>
      as.data.frame() |>
      mutate(variable = colnames(forest$X.orig)) |>
      arrange(desc(V1)) |>
      rename(importance = V1)
  }, error = function(e) NULL)

  list(
    wave = wave_name,
    rate = rate_result,
    var_importance = var_imp
  )
})
names(hetero_results) <- significant_waves

# summarise ---------------------------------------------------------------
for (wave_name in significant_waves) {
  hr <- hetero_results[[wave_name]]
  if (is.null(hr)) next

  cli::cli_h2(sprintf("wave %s", wave_name))

  if (!is.null(hr$rate)) {
    cli::cli_alert_info(sprintf("RATE estimate: %.4f (p = %.4f)",
      hr$rate$estimate, hr$rate$p.value))
  }

  if (!is.null(hr$var_importance)) {
    cli::cli_alert_info("top 5 variables by importance:")
    print(head(hr$var_importance, 5))
  }
}

# save --------------------------------------------------------------------
margot::here_save(hetero_results, "hetero_results", push_mods)
margot::here_save(significant_waves, "significant_waves", push_mods)

cli::cli_h1("script 05 complete - heterogeneity analysis saved")
"####
    .to_string()
}

fn script_06() -> String {
    r####"# 06-positivity.R
# check positivity at each wave
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, kableExtra, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# load saved objects ------------------------------------------------------
wave_datasets <- margot::here_read("wave_datasets", push_mods)
outcome_waves <- margot::here_read("outcome_waves")
name_exposure <- margot::here_read("name_exposure")

cli::cli_h1("positivity checks")

# exposure distribution at each wave --------------------------------------
positivity_summary <- map_dfr(outcome_waves, function(wave_name) {
  dat <- wave_datasets[[wave_name]]
  if (is.null(dat)) return(NULL)

  tibble(
    wave = wave_name,
    n_total = nrow(dat),
    n_exposed = sum(dat$exposed),
    n_control = sum(dat$exposed == 0),
    prop_exposed = mean(dat$exposed),
    time_since_event = unique(dat$time_since_event)
  )
})

print(positivity_summary)

# check for potential violations ------------------------------------------
violations <- positivity_summary |>
  filter(prop_exposed < 0.05 | prop_exposed > 0.95)

if (nrow(violations) > 0) {
  cli::cli_alert_warning("potential positivity violations detected:")
  print(violations)
} else {
  cli::cli_alert_success("no obvious positivity violations")
}

# save --------------------------------------------------------------------
margot::here_save(positivity_summary, "positivity_summary", push_mods)

cli::cli_h1("script 06 complete")
"####
    .to_string()
}

fn script_07() -> String {
    r####"# 07-tables.R
# summary statistics tables
# generated by margo

set.seed(42)

# libraries ---------------------------------------------------------------
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}
library(margot)

if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")
pacman::p_load(
  tidyverse, qs, here, kableExtra, table1, cli, RcppTOML
)

# helpers -----------------------------------------------------------------
`%||%` <- function(x, y) if (!is.null(x)) x else y

require_cfg <- function(x, msg) {
  if (is.null(x)) stop(msg, call. = FALSE)
  x
}

# config ------------------------------------------------------------------
config_path <- here::here("study.toml")
cfg <- RcppTOML::parseTOML(config_path)
push_mods <- require_cfg(cfg$paths$push_mods, "set paths.push_mods")

# load saved objects ------------------------------------------------------
dat_analysis_base <- margot::here_read("dat_analysis_base", push_mods)
baseline_vars <- margot::here_read("baseline_vars")
outcome_var <- margot::here_read("outcome_var")
ate_trajectory <- margot::here_read("ate_trajectory", push_mods)

cli::cli_h1("generating summary tables")

# table 1: baseline characteristics by exposure status --------------------
dat_table1 <- dat_analysis_base |>
  mutate(exposure_group = factor(exposed, levels = c(0, 1),
                                 labels = c("Control", "Exposed")))

baseline_cols <- baseline_vars[baseline_vars %in% names(dat_table1)]

if (length(baseline_cols) > 0) {
  cli::cli_alert_info("baseline characteristics by exposure status:")

  tbl1 <- dat_table1 |>
    select(exposure_group, all_of(baseline_cols)) |>
    group_by(exposure_group) |>
    summarise(across(everything(),
      list(mean = ~mean(., na.rm = TRUE), sd = ~sd(., na.rm = TRUE))),
      .groups = "drop")

  print(tbl1)
  margot::here_save(tbl1, "table_baseline", push_mods)
}

# table 2: ATE trajectory summary -----------------------------------------
cli::cli_alert_info("ATE trajectory summary:")

tbl_trajectory <- ate_trajectory |>
  mutate(
    ate_formatted = sprintf("%.3f (%.3f)", ate, se),
    ci_formatted = sprintf("[%.3f, %.3f]", ci_lower, ci_upper),
    significant = ifelse(ci_lower > 0 | ci_upper < 0, "*", "")
  ) |>
  select(wave, time_since_event, n_total, ate_formatted, ci_formatted, significant)

print(tbl_trajectory)
margot::here_save(tbl_trajectory, "table_trajectory", push_mods)

cli::cli_h1("script 07 complete - tables saved")
"####
    .to_string()
}
